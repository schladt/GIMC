{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/projects/GIMC/env/lib/python3.12/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Sampler\n",
    "from torchdata.datapipes.iter import IterableWrapper\n",
    "\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, select, MetaData, Table, and_\n",
    "\n",
    "from utils.batch import BatchSamplerSimilarLength, collate_batch\n",
    "from utils.train import train_model, compute_accuracy\n",
    "from utils.plot import plot_accuracy, plot_training_loss\n",
    "\n",
    "from models.lstm import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../settings.json') as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "db_uri = settings['sqlalchemy_database_uri']\n",
    "\n",
    "RANDOM_SEED = 4321\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(line):\n",
    "    line = line.lower()\n",
    "    line = line.replace(',', ' ')\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    line = line.replace('\\\\\\\\', ' ')\n",
    "    return line.split()\n",
    "\n",
    "tokenizer = custom_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of signatures to load from database\n",
    "signatures = ['AgentTesla', 'RedLineStealer', 'RaccoonStealer', 'benign']\n",
    "for signature in signatures:\n",
    "    # check if json files exist\n",
    "    if not os.path.isfile(f'{signature}_reports.json'):\n",
    "        # connect to database\n",
    "        engine = create_engine(db_uri)\n",
    "\n",
    "        # load tables\n",
    "        metadata_obj = MetaData()\n",
    "        conn = engine.connect()\n",
    "\n",
    "        Tag = Table('tag', metadata_obj, autoload_with=engine)\n",
    "        SampleTag = Table('sample_tag', metadata_obj, autoload_with=engine)\n",
    "        Analysis = Table('analysis', metadata_obj, autoload_with=engine)\n",
    "\n",
    "        # Start a session\n",
    "        session = Session(engine)\n",
    "\n",
    "        reports = []\n",
    "        bad_reports = []\n",
    "    \n",
    "        # get all reports with the tag of signature\n",
    "        stmt = select(Analysis.c.report).join(SampleTag, Tag.c.id == SampleTag.c.tag_id).join(\n",
    "            Analysis, SampleTag.c.sample_id == Analysis.c.sample).where(and_(\n",
    "            (Tag.c.value == signature),\n",
    "            (Analysis.c.status == 2)\n",
    "        ))\n",
    "\n",
    "        results = session.execute(stmt).fetchall()\n",
    "        print(f\"Found {len(results)} {signature} reports\")\n",
    "        report_paths = [r[0] for r in results] \n",
    "        # Close the session\n",
    "        session.close()\n",
    "\n",
    "        # fetch reports\n",
    "        for report_path in tqdm(report_paths, desc=f\"Reading {signature} reports\"):\n",
    "            try:\n",
    "                with open(report_path) as f:\n",
    "                    r = f.read()\n",
    "                    # tag and append report\n",
    "                    reports.append([r, signature])\n",
    "            except:\n",
    "                bad_reports.append(report_path)\n",
    "                print(f\"Error reading {signature} report: {report_path}. Error number {len(bad_reports)}\")\n",
    "                continue\n",
    "\n",
    "        # shuffle reports\n",
    "        random.shuffle(reports)\n",
    "\n",
    "        # Tokenize reports\n",
    "        i = 0\n",
    "        for report in tqdm(reports, desc=\"Tokenizing reports\"):\n",
    "            dynamic_report = json.loads(report[0])['dynamic']\n",
    "            dynamic_report_tokenized = []\n",
    "            for item in dynamic_report:\n",
    "                line = f\"{item['Operation']}, {item['Path']}, {item['Result']}\"\n",
    "                dynamic_report_tokenized.extend(tokenizer(line))\n",
    "            reports[i][0] = dynamic_report_tokenized\n",
    "            i += 1\n",
    "\n",
    "        # json dump reports to file\n",
    "        print(\"Dumping reports to file\")\n",
    "        with open(f'{signature}_reports.json', 'w') as f:\n",
    "            json.dump(reports, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of signatures to load from database\n",
    "signatures = ['AgentTesla', 'RedLineStealer', 'RaccoonStealer', 'benign']\n",
    "reports = []\n",
    "for signature in signatures:\n",
    "    with open(f'{signature}_reports.json') as f:\n",
    "        r = json.load(f)\n",
    "        reports.extend(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reports)\n",
    "# pre-clean reports by removing any reports less than 1,000 or more than 1,000,000 tokens\n",
    "reports = [r for r in reports if len(r[0]) > 1000 and len(r[0]) < 1000000]\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "std_thres = 0.5\n",
    "\n",
    "# find the mean, median, min, and max lengths of the reports for each signature\n",
    "for signature in signatures:\n",
    "    report_lengths = [len(r[0]) for r in reports if r[1] == signature]\n",
    "    mean_length = np.mean(report_lengths)\n",
    "    median_length = np.median(report_lengths)\n",
    "    min_length = min(report_lengths)\n",
    "    max_length = max(report_lengths)\n",
    "    std_dev = np.std(report_lengths)\n",
    "\n",
    "    print(f\"Number ofreports for {signature}: {len(report_lengths)}\")\n",
    "    print(f\"Mean report length for {signature}: {mean_length}\")\n",
    "    print(f\"Median report length for {signature}: {median_length}\")\n",
    "    print(f\"Min report length for {signature}: {min_length}\")\n",
    "    print(f\"Max report length for {signature}: {max_length}\")\n",
    "    print(f\"Standard deviation for {signature}: {std_dev}\")\n",
    "\n",
    "    # find the outliers in the report lengths based on standard deviation\n",
    "\n",
    "    outliers = [r for r in report_lengths if (r > mean_length + (std_thres * std_dev) or r < mean_length - (std_thres * std_dev))]\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "\n",
    "    # graph distribution of the report lengths before removing outliers\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(report_lengths, bins=1000)\n",
    "    plt.xlabel('Report Length')\n",
    "    plt.ylabel('Number of Reports')\n",
    "    plt.title(f'Report Length Distribution for {signature} Reports')\n",
    "    plt.show()\n",
    "\n",
    "    # remove outliers\n",
    "    reports = [r for r in reports if len(r[0]) not in outliers]\n",
    "    report_lengths = [len(r[0]) for r in reports if r[1] == signature]\n",
    "\n",
    "    # graph distribution of the report lengths after removing outliers\n",
    "    plt.hist(report_lengths, bins=100)\n",
    "    plt.xlabel('Report Length')\n",
    "    plt.ylabel('Number of Reports')\n",
    "    plt.title(f'Report Length Distribution for {signature} Reports')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of reports for each signature after removing outliers\n",
    "for signature in signatures:\n",
    "    report_lengths = [len(r[0]) for r in reports if r[1] == signature]\n",
    "    print(f\"Number of reports for {signature}: {len(report_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle and select 5000 of each signature\n",
    "random.shuffle(reports)\n",
    "selected_reports = []\n",
    "for signature in signatures:\n",
    "    selected_reports.extend([r for r in reports if r[1] == signature][:5000])\n",
    "reports = selected_reports\n",
    "\n",
    "# print the number of reports for each signature after selecting 5000 of each\n",
    "for signature in signatures:\n",
    "    report_lengths = [len(r[0]) for r in reports if r[1] == signature]\n",
    "    print(f\"Number of reports for {signature}: {len(report_lengths)}\")\n",
    "\n",
    "print(f\"Total number of reports: {len(reports)}\")\n",
    "random.shuffle(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total number of unique tokens in all reports\n",
    "from collections import Counter\n",
    "token_counter = Counter()\n",
    "for report in reports:\n",
    "    token_counter.update(report[0])\n",
    "\n",
    "print(f\"Total number of unique tokens: {len(token_counter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation, and test sets\n",
    "dp = IterableWrapper(reports)\n",
    "\n",
    "# Get the number of rows in dataset\n",
    "N_ROWS = len(list(dp)) \n",
    "N_train = int(N_ROWS * 0.8)\n",
    "N_valid = int(N_ROWS * 0.1)\n",
    "N_test = N_ROWS - N_train - N_valid\n",
    "\n",
    "# Split into training and val datapipes early on. Will build vocabulary from training datapipe only.\n",
    "train_dp, valid_dp, test_dp = dp.random_split(total_length=N_ROWS, weights={\"train\": N_train, \"valid\": N_valid, \"test\": N_test}, seed=RANDOM_SEED)\n",
    "\n",
    "print(f'Num Train: {len(train_dp)}')\n",
    "print(f'Num Validate: {len(valid_dp)}')\n",
    "print(f'Num Test: {len(test_dp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield text\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dp), specials=[\"<unk>\", \"<pad>\"], max_tokens=VOCABULARY_SIZE)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "PADDING_VALUE=vocab['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define text and label transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = lambda x: [vocab[token] for token in x]\n",
    "\n",
    "# label transform for 4 classes\n",
    "label_transform = lambda x: 0 if x == signatures[0] else 1 if x == signatures[1] else 2 if x == signatures[2] else 3\n",
    "\n",
    "# # Print out the output of text_transform\n",
    "# print(\"input to the text_transform:\", \"here is an example\")\n",
    "# print(\"output of the text_transform:\", text_transform(list(train_dp)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching wrapper\n",
    "def collate_batch_wrapper(batch):\n",
    "    return collate_batch(batch=batch, \n",
    "                  padding_value=PADDING_VALUE, \n",
    "                  device=DEVICE, \n",
    "                  text_transform=text_transform, \n",
    "                  label_transform=label_transform)\n",
    "\n",
    "# set up dataloaders\n",
    "train_dp_list = list(train_dp)\n",
    "valid_dp_list = list(valid_dp)\n",
    "test_dp_list = list(test_dp)\n",
    "\n",
    "train_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = train_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                          collate_fn=collate_batch_wrapper)\n",
    "valid_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = valid_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  shuffle=False),\n",
    "                          collate_fn=collate_batch_wrapper)\n",
    "test_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = test_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  shuffle=False),\n",
    "                          collate_fn=collate_batch_wrapper)\n",
    "\n",
    "text_batch, label_batch = next(iter(train_loader))\n",
    "print(text_batch.size())\n",
    "print(label_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train')\n",
    "for text_batch, label_batch in train_loader:\n",
    "    print(f'Text matrix size: {text_batch.size()}')\n",
    "    print(f'Target vector size: {label_batch.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nValid:')\n",
    "for text_batch, label_batch in valid_loader:\n",
    "    print(f'Text matrix size: {text_batch.size()}')\n",
    "    print(f'Target vector size: {label_batch.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for text_batch, label_batch in test_loader:\n",
    "    print(f'Text matrix size: {text_batch.size()}')\n",
    "    print(f'Target vector size: {label_batch.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=len(vocab),\n",
    "             embedding_dim=EMBEDDING_DIM,\n",
    "             hidden_dim=HIDDEN_DIM,\n",
    "             output_dim=NUM_CLASSES # could use 1 for binary classification\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    logging_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=100)\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model, vocab, and optimizer state\n",
    "torch.save(model.state_dict(), 'model_data/lstm_mal.pt')\n",
    "torch.save(optimizer.state_dict(), 'model_data/optimizer_mal.pt')\n",
    "\n",
    "# save the vocab\n",
    "with open('model_data/vocab_mal.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, sentence):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if type(sentence) == str:\n",
    "            tokenized = tokenizer(sentence)\n",
    "        elif type(sentence) == list:\n",
    "            tokenized = sentence\n",
    "        else:\n",
    "            raise TypeError('sentence must be str or list')\n",
    "        indexed = [vocab[t] for t in tokenized]\n",
    "        # print(indexed)\n",
    "        length = [len(indexed)]\n",
    "        tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        prediction = F.softmax(model(tensor), dim=1)\n",
    "    return prediction.to(\"cpu\").squeeze(dim=0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    report = random.choice(test_dp_list)\n",
    "    prediction = get_prediction(model, report[0])\n",
    "    print(f\"Report: {label_transform(report[1])}, Prediction: {prediction.argmax()}, {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
