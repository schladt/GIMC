{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736d8e1b",
   "metadata": {},
   "source": [
    "# Genetic Improvement Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7d361",
   "metadata": {},
   "source": [
    "### Create the initial population of Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e175ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os, sys\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "# set the project root directory (~/projects/GIMC)\n",
    "project_root = os.path.expanduser(\"~/projects/GIMC\")\n",
    "\n",
    "# add project root to sys.path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# project imports\n",
    "from genetic_improvement.ollamachat import OllamaChat\n",
    "from genetic_improvement.config import USER_PROMPT, UNIT_TEST_CODE, SYSTEM_PROMPT, NUM_VARIANTS, BSI_CLASSIFICATION\n",
    "from genetic_improvement.genome import Genome\n",
    "\n",
    "# CONSTS\n",
    "POPULATION_SIZE = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011da216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:24<01:38, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:00<01:34, 31.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:28<00:59, 29.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:59<00:30, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:40<00:00, 32.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n",
      "Code submitted successfully. Server response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get the initial population from the LLM\n",
    "population = []\n",
    "for i in tqdm(range(POPULATION_SIZE // NUM_VARIANTS)):\n",
    "    ollama_chat = OllamaChat(model=\"qwen3-coder:latest\", system_prompt=SYSTEM_PROMPT, temperature=0.3)\n",
    "    chat_response = ollama_chat.chat(user_text=USER_PROMPT, stream=False)\n",
    "\n",
    "    # parse the chat response and add it to the population\n",
    "    variants = OllamaChat.parse_variants(chat_response)\n",
    "    candidates = OllamaChat.submit_variants(variants, classification=BSI_CLASSIFICATION)\n",
    "    for candidate in candidates:\n",
    "        if candidate is not None:\n",
    "            genome = Genome(candidate_hash=candidate)\n",
    "            population.append(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d58b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate f410b5bddf4ad9a26c9c5ac4f8971fabd76721a5d818c1279340f135bf1ff32c\n",
      "Candidate bf0b08e59068bef1f6b485b6944a204e2cf51e8a64e15457ebb63af725cb2114\n",
      "Candidate f88af3bce6b8859ae1ac5212949cec62c0db6c746fdaaa311390ea381278929b\n",
      "Candidate 3d0df34679f5500e84948e33baeb59577a4261e212b6df1357bbe9126c6d3c6a\n",
      "Candidate 1072a2f6e74ffa177ecb5ad7f5740c842e64b45c5f159870228d368864d0b31a\n",
      "Candidate 7ee2fce9df7c8df2e4edcd9223da33cb66cb2dcd85f67e42a22ca9a21f155525\n",
      "Candidate 3cacfe0dd7fadcfba225bab0308ddbf836247d1259991ebf909d22803373df1c\n",
      "Candidate 40022fc797da2bfa1a53391e94dbeb6aa6225fa1280e71c27d60a3f3b37a4eac\n",
      "Candidate 869691802c9310db29477838b8c563521ce3d59373495026c33a90800af16570\n",
      "Candidate 96da38f624835c3cfa629fff1d47a898e783a817ae34e158cf0b6f47f603a539\n",
      "Candidate 2ed4b2553827cb039c004a83ebb89620c700ac3a02d396eee0d6f6f0404f3168\n",
      "Candidate 059ba64e55c6d24dc50cdc082e4890d04767b07dcea200715e09ce559ffef90e\n",
      "Candidate 9eeff08a8d10fc1a3a349f34570dbcb511456e3904449dc00a5bd64191ea5c94\n",
      "Candidate 72f3260a0b195c25806ad23009130630413f3e98396da82fdd965e68115334a1\n",
      "Candidate 7479455960aca8d58ada2c38a6fa9485af1fdc65e0c0c20312d7db7d27bca945\n",
      "Candidate 1b6d3c3d853e9d86e12f03d70341c9b9f9f9c3e8e91e9cd47243fdc437e661b5\n",
      "Candidate 74fc68115fb40cb3b7ab666ad308fc3d2732807380a29c4f434d1d6947898a4b\n",
      "Candidate e619e4a78b38f11a77d1afc491d8f2a1758da042a7392e4ff2962abdec84f3ed\n",
      "Candidate 75e798e0aac288bff1f3202f792128d352f764439c69f75f74c133e9e0a80d6f\n",
      "Candidate 3308bae590bbe5bff0e568327268bbf7ef09a0878659284114a782398b25f6f1\n"
     ]
    }
   ],
   "source": [
    "# get the status of each candidate in the population\n",
    "for genome in population:\n",
    "    print(f\"Candidate {genome.candidate_hash}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
