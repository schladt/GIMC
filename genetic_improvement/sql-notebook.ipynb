{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277ca748",
   "metadata": {},
   "source": [
    "## Setup - Import modules and setup database connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219de2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules and setup database connection\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# change to parent directory\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "# print current directory\n",
    "settings_file = 'settings.json'\n",
    "with open(settings_file) as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "# Database setup\n",
    "DATABASE_URL = settings['sqlalchemy_database_uri']\n",
    "engine = create_engine(DATABASE_URL, echo=False)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "from models import Sample, Tag, Analysis, Ingredient, Candidate\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f4a15",
   "metadata": {},
   "source": [
    "## Count all major entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1621c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import Sample, Tag, Analysis, Ingredient, Candidate\n",
    "\n",
    "# Database setup\n",
    "DATABASE_URL = settings['sqlalchemy_database_uri']\n",
    "engine = create_engine(DATABASE_URL, echo=False)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f182c",
   "metadata": {},
   "source": [
    "## Get tags and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5030964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tag Sample Counts:\n",
      "Tag: family=bsi, Sample Count: 3\n",
      "Tag: tatic=scheduled_task, Sample Count: 3\n",
      "Tag: ttp=wmi, Sample Count: 1\n",
      "Tag: ttp=com, Sample Count: 1\n",
      "Tag: ttp=cmd, Sample Count: 1\n",
      "Tag: family=benign, Sample Count: 5908\n",
      "Tag: class=wmi, Sample Count: 15\n",
      "Tag: class=purple, Sample Count: 1\n",
      "Tag: class=cow, Sample Count: 1\n",
      "Tag: class=com, Sample Count: 8\n",
      "Tag: class=cmd, Sample Count: 5\n"
     ]
    }
   ],
   "source": [
    "# get tags and their associated sample counts\n",
    "session.expire_all()\n",
    "from models import sample_tag\n",
    "tags = session.query(Tag).all()\n",
    "tag_sample_counts = {}\n",
    "for tag in tags:\n",
    "    sample_count = session.query(Sample).join(sample_tag).filter(sample_tag.c.tag_id == tag.id).count()\n",
    "    tag_sample_counts[(tag.key, tag.value)] = sample_count\n",
    "print(\"\\nTag Sample Counts:\")\n",
    "for tag_value, sample_count in tag_sample_counts.items():\n",
    "    print(f\"Tag: {tag_value[0]}={tag_value[1]}, Sample Count: {sample_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10a3128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples with tag (class=wmi):\n",
      "Sample ID: 3e538fdd57f368e3cbd31c14a9e1e6880c81e94c93282871c903020471a14190, Name: /mnt/data/gimc/3e/3e53/3e538fdd57f368e3cbd31c14a9e1e6880c81e94c93282871c903020471a14190\n",
      "Sample ID: f2a839f3eac858ddb450a162a9faa6fe54391fb0f0b0c715584cffe36db6e191, Name: /mnt/data/gimc/f2/f2a8/f2a839f3eac858ddb450a162a9faa6fe54391fb0f0b0c715584cffe36db6e191\n",
      "Sample ID: b788d12fed5dd6ad3c0331ee21e8b4c7f568b7f38116457a83370875a1315971, Name: /mnt/data/gimc/b7/b788/b788d12fed5dd6ad3c0331ee21e8b4c7f568b7f38116457a83370875a1315971\n",
      "Sample ID: 79a9409ff29b2e967161e01a0f27bcb0153a66a604e667120e30a8c09ca8deef, Name: /mnt/data/gimc/79/79a9/79a9409ff29b2e967161e01a0f27bcb0153a66a604e667120e30a8c09ca8deef\n",
      "Sample ID: c38bf4cb95005533dd52991b059bfbc60a13f81590e04735bd8a5ace221ee14b, Name: /mnt/data/gimc/c3/c38b/c38bf4cb95005533dd52991b059bfbc60a13f81590e04735bd8a5ace221ee14b\n",
      "Sample ID: 6a181382dbbf14cdab0262153bf0bcc85957f95b8d720ebe93295fe520b7cdd1, Name: /mnt/data/gimc/6a/6a18/6a181382dbbf14cdab0262153bf0bcc85957f95b8d720ebe93295fe520b7cdd1\n",
      "Sample ID: 49fa19821dc17169120ff0160580ba0053ac882f263e5d94a5fa9dd26bb1eba3, Name: /mnt/data/gimc/49/49fa/49fa19821dc17169120ff0160580ba0053ac882f263e5d94a5fa9dd26bb1eba3\n",
      "Sample ID: d078cb881b19d2e9ed54fe04985cf59f153ea14d33b20668817d44488915c019, Name: /mnt/data/gimc/d0/d078/d078cb881b19d2e9ed54fe04985cf59f153ea14d33b20668817d44488915c019\n",
      "Sample ID: 3d4049c241b839a3bb2761f634031ae53f4d7dcf7735cf035db036a3fb6cec8d, Name: /mnt/data/gimc/3d/3d40/3d4049c241b839a3bb2761f634031ae53f4d7dcf7735cf035db036a3fb6cec8d\n",
      "Sample ID: d7ba362f09d27820cee2a6a05140d02ee89b1c362c5378c41d0931a35341238e, Name: /mnt/data/gimc/d7/d7ba/d7ba362f09d27820cee2a6a05140d02ee89b1c362c5378c41d0931a35341238e\n",
      "Sample ID: ba3365452639c40e6c18255896f5d10d12d18335d7be2e1610d0b37b7575e944, Name: /mnt/data/gimc/ba/ba33/ba3365452639c40e6c18255896f5d10d12d18335d7be2e1610d0b37b7575e944\n",
      "Sample ID: 33afdf087ac21472ea67b68d1a7038ad5e170a4fc5561d4affee2a5066c7ee72, Name: /mnt/data/gimc/33/33af/33afdf087ac21472ea67b68d1a7038ad5e170a4fc5561d4affee2a5066c7ee72\n",
      "Sample ID: 2e5ce94e324f3cda8e0da23f9b71387f7c4f13793c22eb9df180e61946c425f1, Name: /mnt/data/gimc/2e/2e5c/2e5ce94e324f3cda8e0da23f9b71387f7c4f13793c22eb9df180e61946c425f1\n",
      "Sample ID: 08e482398578949fd9a23e8a7f8090a225d4801a738eb6de2dae083a3c4bff58, Name: /mnt/data/gimc/08/08e4/08e482398578949fd9a23e8a7f8090a225d4801a738eb6de2dae083a3c4bff58\n",
      "Sample ID: 1cf0572c7b6958c489da7e5c1108e46d5609740111ab7946caffdf1f9c087c6f, Name: /mnt/data/gimc/1c/1cf0/1cf0572c7b6958c489da7e5c1108e46d5609740111ab7946caffdf1f9c087c6f\n"
     ]
    }
   ],
   "source": [
    "# get all samples asscoiated with a specific tag\n",
    "session.expire_all()\n",
    "\n",
    "tag_key = 'class'\n",
    "tag_value = 'wmi'\n",
    "samples_with_tag = session.query(Sample).join(sample_tag).join(Tag).filter(Tag.key == tag_key, Tag.value == tag_value).all()\n",
    "print(f\"\\nSamples with tag ({tag_key}={tag_value}):\")\n",
    "for sample in samples_with_tag:\n",
    "    print(f\"Sample ID: {sample.sha256}, Name: {sample.filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7651b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates in the database: 0\n",
      "Number of samples in the database: 5944\n",
      "Number of analyses in the database: 17878\n"
     ]
    }
   ],
   "source": [
    "count_Candidates = session.query(Candidate).count()\n",
    "count_samples = session.query(Sample).count()\n",
    "count_Analyses = session.query(Analysis).count()\n",
    "count_Tags = session.query(Tag).count()\n",
    "count_Ingredients = session.query(Ingredient).count()\n",
    "\n",
    "print(f\"Number of candidates in the database: {count_Candidates}\")\n",
    "print(f\"Number of samples in the database: {count_samples}\")\n",
    "print(f\"Number of analyses in the database: {count_Analyses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3868b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Status Counts:\n",
      "Status: 2, Count: 17331\n",
      "Status: 3, Count: 547\n"
     ]
    }
   ],
   "source": [
    "# get counts of all statuses of analyses\n",
    "session.expire_all()\n",
    "\n",
    "from sqlalchemy import func\n",
    "analysis_status_counts = session.query(Analysis.status, func.count(Analysis.id)).group_by(Analysis.status).all()\n",
    "print(\"\\nAnalysis Status Counts:\")\n",
    "for status, count in analysis_status_counts:\n",
    "    print(f\"Status: {status}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4ff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyses for sample with SHA256 f2a839f3eac858ddb450a162a9faa6fe54391fb0f0b0c715584cffe36db6e191:\n",
      "Analysis ID: 17848, Status: 2\n"
     ]
    }
   ],
   "source": [
    "# get analysis by sample sha256\n",
    "session.expire_all()\n",
    "\n",
    "sample_sha256 = 'f2a839f3eac858ddb450a162a9faa6fe54391fb0f0b0c715584cffe36db6e191'\n",
    "analysis_for_sample = session.query(Analysis).join(Sample).filter(Sample.sha256 == sample_sha256).all()\n",
    "print(f\"\\nAnalyses for sample with SHA256 {sample_sha256}:\")\n",
    "for analysis in analysis_for_sample:\n",
    "    print(f\"Analysis ID: {analysis.id}, Status: {analysis.status}\")\n",
    "if not analysis_for_sample:\n",
    "    print(\"No analyses found for this sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05105727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis ID: 17849, Status: 2, Sample ID: b788d12fed5dd6ad3c0331ee21e8b4c7f568b7f38116457a83370875a1315971\n"
     ]
    }
   ],
   "source": [
    "# get analysis by its ID\n",
    "session.expire_all()\n",
    "\n",
    "analysis_id = 17849  # replace with desired analysis ID\n",
    "analysis = session.query(Analysis).filter(Analysis.id == analysis_id).first()\n",
    "if analysis:\n",
    "    print(f\"\\nAnalysis ID: {analysis.id}, Status: {analysis.status}, Sample ID: {analysis.sample}\")\n",
    "else:\n",
    "    print(f\"\\nNo analysis found with ID {analysis_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8cfc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidates:\n",
      "Candidate ID: 95bb77e5e87811eb21cd17dcdddbcda388125ba3da7d5b6df5860eac732ae09b, Status: 3, F1: 0.14285714285714285, F2: 0.0, F3: 0.0, Analysis ID: None, Error: Compilation failed: 2 errors, 0 warnings, Class Tag: wmi\n",
      "Candidate ID: 33b2547820326675e8356ec6cad137b52e1b57990e66e180b4089356c7753b43, Status: 3, F1: 0.047619047619047616, F2: 1.0, F3: 0.9981977343559265, Analysis ID: 17886, Error: None, Class Tag: cmd\n",
      "Candidate ID: a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b, Status: 3, F1: 1.0, F2: 1.0, F3: 0.989303469657898, Analysis ID: 17887, Error: None, Class Tag: com\n",
      "Candidate ID: baa9f40b8d15fd64663654eb3c7f299fb33b904d6a8d3fd0918fbef8a162f86b, Status: 3, F1: 0.14285714285714285, F2: 0.0, F3: 0.0, Analysis ID: None, Error: Compilation failed: 2 errors, 0 warnings, Class Tag: com\n"
     ]
    }
   ],
   "source": [
    "# get candidates\n",
    "session.expire_all()\n",
    "\n",
    "candidates = session.query(Candidate).all()\n",
    "print(\"\\nCandidates:\")\n",
    "for candidate in candidates:\n",
    "    print(f\"Candidate ID: {candidate.hash}, Status: {candidate.status}, F1: {candidate.F1}, F2: {candidate.F2}, F3: {candidate.F3}, Analysis ID: {candidate.analysis_id}, Error: {candidate.error_message}, Classification: {candidate.classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4921f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated candidate a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b to status '0'.\n"
     ]
    }
   ],
   "source": [
    "# # update status of a candidate to 0\n",
    "# session.expire_all()\n",
    "\n",
    "# candidate_hash = 'a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b'  # replace with actual candidate hash\n",
    "# candidate = session.query(Candidate).filter(Candidate.hash == candidate_hash).first()\n",
    "# if candidate:\n",
    "#     candidate.status = 0  # replace with desired status\n",
    "#     candidate.F1 = None\n",
    "#     candidate.F2 = None\n",
    "#     candidate.F3 = None\n",
    "#     candidate.analysis_id = None\n",
    "#     candidate.error_message = None\n",
    "#     session.commit()\n",
    "#     print(f\"\\nUpdated candidate {candidate_hash} to status '{candidate.status}'.\")\n",
    "# else:\n",
    "#     print(f\"\\nNo candidate found with hash {candidate_hash}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef331e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate Details for a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b:\n",
      "Hash: a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b\n",
      "Status: 3\n",
      "F1: 1.0\n",
      "F2: 1.0\n",
      "F3: 0.989303469657898\n",
      "Tags: [{'key': 'class', 'value': 'wmi'}, {'key': 'class', 'value': 'com'}]\n",
      "Analysis ID: 17887\n",
      "Code Snippet: #include <windows.h>\n",
      "#include <comdef.h>\n",
      "#include <Wbemidl.h>\n",
      "#include <iostream>\n",
      "\n",
      "#define INSTALL_NAME L\"GIMCTestBSI\"\n",
      "#define TIMER_INTERVAL 2000  // 2 seconds in milliseconds\n",
      "\n",
      "// Simple benign payload - writes timestamp to file to demonstrate persistence\n",
      "const wchar_t* PAYLOAD_SCRIPT = \n",
      "    L\"var fso = new ActiveXObject('Scripting.FileSystemObject');\"\n",
      "    L\"var logFile = 'C:\\\\\\\\Users\\\\\\\\Public\\\\\\\\gimc_test.log';\"\n",
      "    L\"var f = fso.OpenTextFile(logFile, 8, true);\"\n",
      "    L\"var d = new Date();\"\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# get full candidate details\n",
    "session.expire_all()\n",
    "\n",
    "import base64\n",
    "candidate_hash = 'a4e381fdab1f71481eb33e09e9528800234c7da84a6d30f63f3339b20c03e71b'  # replace with actual candidate hash\n",
    "candidate = session.query(Candidate).filter(Candidate.hash == candidate_hash).first()\n",
    "if candidate:\n",
    "    print(f\"\\nCandidate Details for {candidate_hash}:\")\n",
    "    print(f\"Hash: {candidate.hash}\")\n",
    "    print(f\"Status: {candidate.status}\")\n",
    "    print(f\"F1: {candidate.F1}\")\n",
    "    print(f\"F2: {candidate.F2}\")\n",
    "    print(f\"F3: {candidate.F3}\")\n",
    "    print(f\"Classification: {candidate.classification}\")\n",
    "    print(f\"Analysis ID: {candidate.analysis_id}\")\n",
    "    # unbase64 the code snippet and print first XX characters\n",
    "    decoded_code = base64.b64decode(candidate.code).decode('utf-8', errors='ignore')\n",
    "    print(f\"Code Snippet: {decoded_code[:500]}\")\n",
    "else:\n",
    "    print(f\"\\nNo candidate found with hash {candidate_hash}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daaa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample from analysis ID\n",
    "session.expire_all()\n",
    "\n",
    "analysis_id = 5000  # replace with desired analysis ID\n",
    "analysis = session.query(Analysis).filter(Analysis.id == analysis_id).first()\n",
    "if analysis:\n",
    "    sample = session.query(Sample).filter(Sample.sha256 == analysis.sample).first()\n",
    "    if sample:\n",
    "        print(f\"\\nSample for Analysis ID {analysis_id}:\")\n",
    "        print(f\"Sample ID: {sample.sha256}, Name: {sample.filepath}\")\n",
    "    else:\n",
    "        print(f\"\\nNo sample found for Analysis ID {analysis_id}.\")\n",
    "    # get all tags for the sample\n",
    "    tags = session.query(Tag).join(sample_tag).join(Sample).filter(Sample.sha256 == sample.sha256).all()\n",
    "    print(f\"\\nTags for Sample ID {sample.sha256}:\")\n",
    "    for tag in tags:\n",
    "        print(f\"Tag: {tag.key}={tag.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from classifier.models.cnn_nlp import CNN_NLP\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "from transformers import AutoTokenizer\n",
    "classifier_path = '/mnt/data/gimc/classifier/model_data/cnn4bsi_checkpoint.pth'\n",
    "tokenizer_path = '/mnt/data/gimc/classifier/model_data/mal-reformer'\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "TOKENIZER.pad_token = \"[PAD]\"\n",
    "TOKENIZER.cls_token = \"[CLS]\"\n",
    "TOKENIZER.sep_token = \"[SEP]\"\n",
    "\n",
    "checkpoint = torch.load(classifier_path)\n",
    "vocab_size = 20000\n",
    "embed_dim = 128\n",
    "num_classes = 4\n",
    "dropout = 0.5\n",
    "MODEL = CNN_NLP(\n",
    "    pretrained_embedding=None,\n",
    "    freeze_embedding=False,\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    filter_sizes=[3, 4, 5],\n",
    "    num_filters=[10, 10, 10],\n",
    "    num_classes=num_classes,\n",
    "    dropout=dropout\n",
    ")\n",
    "MODEL.load_state_dict(checkpoint['model_states'][-1])\n",
    "MODEL.to(DEVICE)\n",
    "MODEL.eval()\n",
    "\n",
    "def mal_tokenizer(line):\n",
    "    \"\"\"\n",
    "    Tokenize a line of text\n",
    "    \"\"\"\n",
    "    line = line.lower()\n",
    "    line = line.replace(',', ' ')\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    line = line.replace('\\\\\\\\', ' ')\n",
    "    return line.split()\n",
    "\n",
    "dynamic_report_tokenized = []\n",
    "\n",
    "with open(analysis.report) as f:\n",
    "    report = f.read()\n",
    "    dynamic_report = json.loads(report)['dynamic']\n",
    "    for item in dynamic_report:\n",
    "        line = f\"{item['Operation']}, {item['Path']}, {item['Result']}\"\n",
    "        dynamic_report_tokenized.extend(mal_tokenizer(line))\n",
    "\n",
    "report_text = \" \".join(dynamic_report_tokenized)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 20480 * 2\n",
    "inputs = TOKENIZER(\n",
    "    report_text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    return_tensors='pt'\n",
    ").to(DEVICE)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    logits = MODEL(input_ids)\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "# turn props into a list of probabilities\n",
    "probabilities = probs.cpu().numpy().flatten().tolist()\n",
    "print(\"Class Probabilities:\")\n",
    "for i, prob in enumerate(probabilities):\n",
    "    print(f\"Class {i}: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
